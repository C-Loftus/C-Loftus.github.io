---
title: "Creating Dev Tools for Vision Impairments"
date: 2024-01-07T12:24:53-05:00
draft: true
summary: ""
---

A few months ago, I developed some significant eye issues from the amount of computer use I was doing between my job and personal development work. Given the fact that I also use Talon Voice and do the majority of my computer input through voice dictation, I needed to find some way to integrate my workflow with a screen reader. By default, screen readers are significantly more keyboard-intensive compared to sighted computer use. For blind or visually impaired users that develop RSI, they often have to use ad hoc dictation solutions that lack proper screen reader integration.

Voice dictation alongside a screen reader is deceptively difficult. without visual feedback it can be difficult to know if a command was executed correctly. Additionally, many hands free Accessibility tools make up for a loss of hand in put through an increased dependence upon visual indicators, for instance controlling the cursor with eye tracking or labeling UI elements with unique selectors.

beyond these issues, low vision dictation and alternative HCI is a problem with relatively little incentive. Braille displays or licenses for JAWS cost thousands of dollars. compare to other software ventures, there is not significant financial incentive. very often software work is done begrudgingly and as a result is limited in its documentation. it is not a coincidence that the two BEST SCREEN readers for windows, JAWS and NVDA, were both initially created by blind users.

# My Solution

in my life I have increasingly come to realize that friction is perhaps the important tool in our disposal for creating or changing habits. give in the extreme power of friction and the ability of a chronic illness too instantly create it in such large quantities, it would be a mistake to say that the experience of the chronicle ill or disabled is a strict subset to those of the able bodied (if such a category is even valid to begin with).
